{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp charge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PV Forecasting\n",
    "\n",
    "<br>\n",
    "\n",
    "## Battery charging: problem definition\n",
    "\n",
    "The goal of the battery charging component is to maximise the amount of charge that is drawn from solar PV, as opposed to the grid. We want to maximise: \n",
    "\n",
    "$$p_{d,1} = \\frac{\\sum{P_{d,k}}}{\\sum{B_{d,k}}}$$\n",
    "\n",
    "summing over all $k$ periods during which we can charge. We are allowed to charge during $k=1,...31$ or between 00:00 and 15:30 (that is the settlement period ending at 15:30).\n",
    "\n",
    "##### Constraints\n",
    "\n",
    "As with the battery discharge, the battery has a number of constraints. The first constraint is on the maximum import and export of energy, in this case:\n",
    "\n",
    "$$-2.5MW = B_{min} \\leq B_{d, k} \\leq B_{max} = 2.5MW$$\n",
    "\n",
    "Secondly the battery cannot charge beyond its capacity, $C_{d, k}$, (in MWh):\n",
    "\n",
    "$$0 \\leq C_{d, k} \\leq C_{max} = 6MWh$$\n",
    "\n",
    "The total charge in the battery at the next time step $C_{d, k+1}$ is related to how much is currently in the battery and how much charged within the battery at time $k$, i.e.\n",
    "\n",
    "$$C_{d, k+1} = C_{d, k} + 0.5B_{d, k}$$\n",
    "\n",
    "Finally, the battery must start empty at the start of each day in the test week. I.e. $C_{d,1} = 0$ for $d = 1, … , 7$.\n",
    "\n",
    "##### Output\n",
    "\n",
    "The output should be roughly the same as the battery discharge, except with positive values to indicate charging. E.g.\n",
    "\n",
    "```\n",
    "charging_profile = [\n",
    "0, ## 00:00--00:30\n",
    "0, ## 00:30--01:00\n",
    "...\n",
    "1.2, ## 14:30--15:00\n",
    "0.7] ## 15:00--15:30\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4aac9103fa73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmoepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquantile_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'moepy'"
     ]
    }
   ],
   "source": [
    "#exports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from moepy.lowess import quantile_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from batopt import clean\n",
    "from batopt import discharge\n",
    "\n",
    "import FEAutils as hlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should do some investigation of how the panel temp influences performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### User Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = '../data/raw'\n",
    "intermediate_data_dir = '../data/intermediate'\n",
    "cache_data_dir = '../data/nb-cache'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean.combine_training_datasets(intermediate_data_dir).interpolate(limit=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Correlations between the solar variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_cols = [c for c in df.columns if 'solar_location' in c]\n",
    "solar_cols.append('irradiance_Wm-2')\n",
    "solar_cols.append('panel_temp_C')\n",
    "solar_cols.append('pv_power_mw')\n",
    "\n",
    "fig, ax = plt.subplots(dpi=250)\n",
    "df_solar = df.filter(solar_cols).copy()\n",
    "ax = sns.heatmap(df_solar.corr(), cmap='viridis')\n",
    "fig.savefig('../img/solar_corrplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "As in the demand data, estimating the quantiles for the solar PV output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#exports\n",
    "def estimate_daily_solar_quantiles(x, y, x_pred = np.linspace(0, 23.5, 100), **model_kwargs):\n",
    "    # Fitting the model\n",
    "    df_quantiles = quantile_model(x, y, x_pred=x_pred, **model_kwargs)\n",
    "\n",
    "    # Cleaning names and sorting for plotting\n",
    "    df_quantiles.columns = [f'p{int(col*100)}' for col in df_quantiles.columns]\n",
    "    df_quantiles = df_quantiles[df_quantiles.columns[::-1]]\n",
    "    \n",
    "    return df_quantiles\n",
    "\n",
    "dts = df.index.tz_convert('Europe/London')\n",
    "x = np.array(dts.hour + dts.minute/60)\n",
    "y = df['pv_power_mw'].values\n",
    "\n",
    "rerun_daily_solar_model = False\n",
    "daily_solar_filename = 'daily_solar_quantile_model_results.csv'\n",
    "\n",
    "if (rerun_daily_solar_model == True) or (daily_solar_filename not in os.listdir(cache_data_dir)):\n",
    "    df_quantiles = estimate_daily_solar_quantiles(x, y, frac=0.2, num_fits=48, robust_iters=3)\n",
    "    df_quantiles.to_csv(f'{cache_data_dir}/{daily_solar_filename}')\n",
    "else:\n",
    "    df_quantiles = pd.read_csv(f'{cache_data_dir}/{daily_solar_filename}', index_col='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "And plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_jittered = x + (np.random.uniform(size=len(x)) - 0.5)/2.5\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(dpi=250)\n",
    "\n",
    "ax.scatter(x_jittered, y, s=0.2, color='k', alpha=0.5)\n",
    "df_quantiles.plot(cmap='viridis', legend=False, ax=ax)\n",
    "\n",
    "hlp.hide_spines(ax)\n",
    "ax.legend(frameon=False, bbox_to_anchor=(1, 0.9), title='Percentiles')\n",
    "ax.set_xlabel('Time of Day')\n",
    "ax.set_ylabel('Demand (MW)')\n",
    "ax.set_xlim(0, 24)\n",
    "ax.set_ylim(0, 4)\n",
    "\n",
    "fig.savefig('../img/daily_solar_profile.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Proportion of days during which we can fully charge the battery\n",
    "\n",
    "It may be useful to know the proportion of days during which the battery can be fully charged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solar_hrs = df.between_time('00:00:00', '15:00:00')\n",
    "pv_generation = df_solar_hrs.groupby(df_solar_hrs.index.date).sum()['pv_power_mw']*0.5 # available daily energy from PV\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(pv_generation, bins=20)\n",
    "plt.show()\n",
    "\n",
    "prop = np.sum(pv_generation >= 6)/pv_generation.size\n",
    "print(\"Proportion of days where solar generation exceeds 6 MWh: {:.2f}%\".format(prop*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Optimal charging with perfect foresight\n",
    "\n",
    "We will now develop an algorithm to determine the optimal charging schedule given a perfect solar forecast. \n",
    "\n",
    "The scoring function for the generation component rewards us taking as much energy as possible from solar PV. The proportion of energy from PV for a day $d$ is given by $$p_{d,1} = \\frac{\\sum{P_{d,k}}}{\\sum{B_{d,k}}}$$ where we are summing over all periods $k$. An equivalent equation is applies for $p_{d,2}$ which is the energy that is drawn from the grid. The scoring function rewards $p_{d,1}$ over $p_{d,2}$ in a ratio of 3 to 1. \n",
    "\n",
    "Any schedule which fully exploits the solar PV potential until the battery is charged is equally good in terms of the scoring function. However, it may be worth considering methods which give a smoother charge profile for the purposes of producing a robust model for unseen days.\n",
    "\n",
    "In addition, we need to have a method of intelligently allocating charge when the solar PV potential is less than the capacity of the battery.\n",
    "\n",
    "Some possible methods for this:\n",
    "\n",
    "- Naively reallocate over the middle of they day (say 09:00--15:00)\n",
    "- Add charge to periods where charge has already been committed.\n",
    "- Use a forecast for PV output and allocate charge proportionally to the forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_pv = df['pv_power_mw'].dropna()\n",
    "solar_profile = discharge.sample_random_days(s_pv)\n",
    "\n",
    "solar_profile.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "For perfect foresight, any schedule that draws all of the available solar power or 6 MWh (if the total solar production exceeds 6 MWh) is equally good. \n",
    "\n",
    "This first approach will aim to draw greedily from  until 6 MWh is satisfied, or all of the solar production has been expended.\n",
    "\n",
    "In cases where there is not enough solar PV to fill the battery, we will then uniformly add the remaining capacity across all periods.\n",
    "\n",
    "**Note: this seems to work on this dataset but won't if there is a very large spike in solar PV, such topping up uniformly causes a constraint to be violated. It also may not work if the number of periods over which we top up is decreased.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#exports\n",
    "def extract_solar_profile(s_solar_sample_dt, start_time='00:00', end_time='15:00'):\n",
    "    dt = str(s_solar_sample_dt.index[0].date())\n",
    "    solar_profile = s_solar_sample_dt[f'{dt} {start_time}':f'{dt} {end_time}'].values\n",
    "\n",
    "    return solar_profile\n",
    "\n",
    "def charge_profile_greedy(solar_profile, capacity=6, initial_charge=0, max_charge_rate=2.5, time_unit=0.5):\n",
    "    order = np.flip(np.argsort(solar_profile))\n",
    "    charge = initial_charge\n",
    "    solution = np.zeros(len(solar_profile))\n",
    "    for i in order:\n",
    "        solar_available = np.minimum(solar_profile[i], max_charge_rate)\n",
    "        solar_available = min(solar_available, (capacity - charge)/time_unit) \n",
    "        solution[i] = solar_available\n",
    "        charge = np.sum(solution)*time_unit\n",
    "        if charge > capacity:\n",
    "            break\n",
    "    return solution\n",
    "\n",
    "def topup_charge_naive(charge_profile, capacity=6, time_unit=0.5, period_start=16, period_end=30):\n",
    "    charge = np.sum(charge_profile)*time_unit\n",
    "    spare_cap = capacity - charge\n",
    "    topup_value = spare_cap/((period_end-period_start)*time_unit)\n",
    "    new_profile = np.copy(charge_profile)\n",
    "    new_profile[period_start:period_end] += topup_value # Add topup_value uniformly between start and end periods\n",
    "    return new_profile\n",
    "\n",
    "def scale_charge(charge_profile, capacity=6, time_unit=0.5):\n",
    "    \"\"\"\n",
    "    Scale a charging profile to sum to capacity/time_unit while maintaining its shape\n",
    "    \"\"\"\n",
    "    charge_profile = (capacity/time_unit)*charge_profile/np.sum(charge_profile)\n",
    "    return charge_profile\n",
    "\n",
    "def optimal_charge_profile(solar_profile, capacity=6, time_unit=0.5, max_charge_rate=2.5):\n",
    "    solution = charge_profile_greedy(solar_profile)\n",
    "    solution = topup_charge_naive(solution)\n",
    "    assert np.isclose(np.sum(solution), capacity/time_unit), \"Does not meet capacity constraint\".format(np.sum(solution)) \n",
    "    assert np.all(solution <= max_charge_rate), \"Does not meet max charge rate constraint. Max is {}\".format(np.max(solution))\n",
    "    return solution\n",
    "\n",
    "random_solar_profile = discharge.sample_random_day(s_pv).pipe(extract_solar_profile)\n",
    "x = optimal_charge_profile(random_solar_profile) # Note there is sometimes a rounding error here\n",
    "\n",
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The danger with this method is that it can be quite spiky. I wonder if this (a) makes the function difficult to learn (b) is too risky as compared with hedging bets with a more smoother approach. \n",
    "\n",
    "<br>\n",
    "\n",
    "##### Smooth Approach\n",
    "\n",
    "We can use the same peak flattening algorithm developed for the dischrge optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_random_solar_profile = discharge.flatten_peak(random_solar_profile)\n",
    "\n",
    "plt.plot(random_solar_profile)\n",
    "plt.plot(adj_random_solar_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Which we can deduct from the original evening profile to construct the charge profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "construct_charge_profile = lambda solar_profile, adj_solar_profile: solar_profile - adj_solar_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_profile = construct_charge_profile(random_solar_profile, adj_random_solar_profile)\n",
    "\n",
    "plt.plot(charge_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Rather than the sample day we've just used we'll now repeat this step for all days we have pv data on, returning a series of the new charge values that can be easily added to the discharge values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def construct_charge_s(s_pv, start_time='00:00', end_time='15:00'):\n",
    "    s_charge = pd.Series(index=s_pv.index, dtype=float).fillna(0)\n",
    "\n",
    "    for dt in s_pv.index.strftime('%Y-%m-%d').unique():\n",
    "        solar_profile = s_pv[dt].pipe(extract_solar_profile)\n",
    "        adj_solar_profile = discharge.flatten_peak(solar_profile)\n",
    "        \n",
    "        charge_profile = construct_charge_profile(solar_profile, adj_solar_profile)\n",
    "        s_charge[f'{dt} {start_time}':f'{dt} {end_time}'] = charge_profile\n",
    "\n",
    "    return s_charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_charge = construct_charge_s(s_pv, start_time='00:00', end_time='15:00')\n",
    "\n",
    "s_charge.iloc[:48*7].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "With the greedy algorithm we can analyse the periods during which charging occurs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_charge.groupby(s_charge.index.time).mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Unsurprisingly we never charge before 5am. We can therefore truncate our training to just look at 05:00--15:30. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Model development: charging\n",
    "\n",
    "Following the same structure as battery discharge, we will aim to predict the optimal charge schedule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports \n",
    "def construct_df_charge_features(df, dt_rng=None):\n",
    "    if dt_rng is None:\n",
    "        dt_rng = pd.date_range(df.index.min(), df.index.max(), freq='30T')\n",
    "        \n",
    "    df_features = pd.DataFrame(index=dt_rng)\n",
    "    \n",
    "    # Filtering for the temperature weather data\n",
    "    temp_loc_cols = df.columns[df.columns.str.contains('temp_location')]\n",
    "    df_features.loc[df.index, temp_loc_cols] = df[temp_loc_cols].copy()\n",
    "    df_features = df_features.ffill(limit=1)\n",
    "    \n",
    "    # Adding lagged demand\n",
    "    df_features['demand_7d_lag'] = df['demand_MW'].shift(48*7)\n",
    "\n",
    "    # Adding datetime features\n",
    "    dts = df_features.index.tz_convert('Europe/London') # We want to use the 'behavioural' timezone\n",
    "\n",
    "    df_features['weekend'] = dts.dayofweek.isin([5, 6]).astype(int)\n",
    "    df_features['hour'] = dts.hour + dts.minute/60\n",
    "    df_features['doy'] = dts.dayofyear\n",
    "    df_features['dow'] = dts.dayofweek\n",
    "    \n",
    "    # Removing NaN values\n",
    "    df_features = df_features.dropna()\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "#exports\n",
    "def extract_charging_datetimes(df, start_hour=5, end_hour=15):\n",
    "    hour = df.index.hour + df.index.minute/60\n",
    "    charging_datetimes = df.index[(hour>=start_hour) & (hour<=end_hour)]\n",
    "    \n",
    "    return charging_datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def prepare_training_input_data(intermediate_data_dir):\n",
    "    # Loading input data\n",
    "    df = clean.combine_training_datasets(intermediate_data_dir).interpolate(limit=1)\n",
    "    df_features = construct_df_charge_features(df)\n",
    "    \n",
    "    # Filtering for overlapping feature and target data\n",
    "    dt_idx = pd.date_range(df_features.index.min(), df['demand_MW'].dropna().index.max()-pd.Timedelta(minutes=30), freq='30T')\n",
    "\n",
    "    s_pv = df.loc[dt_idx, 'pv_power_mw']\n",
    "    df_features = df_features.loc[dt_idx]\n",
    "    \n",
    "    # Constructing the discharge series\n",
    "    s_charge = construct_charge_s(s_pv, start_time='00:00', end_time='15:00')\n",
    "    \n",
    "    # Filtering for evening datetimes\n",
    "    charging_datetimes = extract_charging_datetimes(df_features)\n",
    "    \n",
    "    X = df_features.loc[charging_datetimes]\n",
    "    y = s_charge.loc[charging_datetimes]\n",
    "    \n",
    "    return X, y, charging_datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, charging_datetimes = prepare_training_input_data(intermediate_data_dir)\n",
    "\n",
    "X.shape, y.shape, charging_datetimes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = clean.generate_kfold_preds(X.values, y.values, LinearRegression(), index=charging_datetimes)\n",
    "\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We need to fix the predictions such that they satisfy the battery constraints. We will do this in the same way as applied in the battery discharge component, first clipping the charge rate to be between 0--2.5MW, then normalising such that the total charge sums to 6 MWh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def normalise_total_charge(s_pred, charge=6., time_unit=0.5):\n",
    "    s_daily_charge = s_pred.groupby(s_pred.index.date).sum()\n",
    "\n",
    "    for date, total_charge in s_daily_charge.items():\n",
    "        s_pred.loc[str(date)] *= (charge/(time_unit*total_charge))\n",
    "        \n",
    "    return s_pred    \n",
    "\n",
    "clip_charge_rate = lambda s_pred, max_rate=2.5, min_rate=0: s_pred.clip(lower=max_rate, upper=min_rate)\n",
    "\n",
    "post_pred_charge_proc_func = lambda s_pred: (s_pred\n",
    "                                      .pipe(clip_charge_rate)\n",
    "                                      .pipe(normalise_total_charge)\n",
    "                                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "post_pred_charge_proc_func(df_pred['pred']).groupby(df_pred.index.date).sum().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Model Comparison Metrics\n",
    "\n",
    "Schedules are scored according to the proportion of the total battery charge that comes from solar: $p_{d,1} = \\frac{\\sum{P_{d,k}}}{\\sum{B_{d,k}}}$.\n",
    "\n",
    "We will first write a function which evaluates this scoring function for a charging schedule and solar profile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def score_charging(schedule, solar_profile):\n",
    "    # The actual pv charge is the minimum of the scheduled charge and the actual solar availability \n",
    "    actual_pv_charge = np.minimum(schedule, solar_profile) \n",
    "    score = np.sum(actual_pv_charge)/np.sum(schedule)\n",
    "    return score\n",
    "\n",
    "# example: \n",
    "df_pred['pred'] = post_pred_charge_proc_func(df_pred['pred'])\n",
    "schedule = discharge.sample_random_day(df_pred['pred'])\n",
    "solar_profile = df.loc[schedule.index]['pv_power_mw']\n",
    "\n",
    "print(\"Score for random day: {}\".format(score_charging(schedule, solar_profile)))\n",
    "\n",
    "# example: \n",
    "schedule = df_pred['pred']\n",
    "solar_profile = df.loc[schedule.index]['pv_power_mw']\n",
    "print(\"Score for entire dataset: {}\".format(score_charging(schedule, solar_profile)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**However** remember that some days there is not enough solar PV to fill the battery. It would be good to know what % of the max score we achieved. That is, the sum of our PV charge over the total available PV capacity (capped at 6 MWh per day). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_available_solar(solar_profile, capacity_mwh=6, time_unit=0.5):\n",
    "    \"\"\"\n",
    "    Return the solar PV potential available to the battery.\n",
    "    \n",
    "    That is, the total PV potential with a daily cap of 6 MWh. \n",
    "    \"\"\"\n",
    "    available = solar_profile.groupby(solar_profile.index.date).sum() * time_unit\n",
    "    clipped = np.clip(available.values, 0, capacity_mwh)\n",
    "    total = np.sum(clipped)\n",
    "    return total \n",
    "\n",
    "max_available_solar(df.loc[schedule.index]['pv_power_mw'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Now we need a function to evaluate a schedule as a proportion of the max available score. That is, the total PV charge used by the battery divided by the total available solar PV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_max_solar(schedule, solar_profile, time_unit=0.5):\n",
    "    actual_pv_charge = np.sum(np.minimum(schedule, solar_profile)*time_unit)\n",
    "    max_pv_charge = max_available_solar(solar_profile)\n",
    "    return actual_pv_charge/max_pv_charge\n",
    "\n",
    "# example: \n",
    "df_pred['pred'] = post_pred_charge_proc_func(df_pred['pred'])\n",
    "schedule = discharge.sample_random_day(df_pred['pred'])\n",
    "solar_profile = df.loc[schedule.index]['pv_power_mw']\n",
    "print(\"Score for random day: {}\".format(prop_max_solar(schedule, solar_profile)))\n",
    "\n",
    "# example: \n",
    "schedule = df_pred['pred']\n",
    "solar_profile = df.loc[schedule.index]['pv_power_mw']\n",
    "print(\"Score for entire dataset: {}\".format(prop_max_solar(schedule, solar_profile)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Model comparison\n",
    "\n",
    "Now let's try some different models and view their scores and the proportion of maximum PV potential:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'std_linear': LinearRegression(),\n",
    "    'random_forest': RandomForestRegressor(),\n",
    "    'boosted': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "for key in models:\n",
    "    df_pred = clean.generate_kfold_preds(X.values, y.values, models[key], index=charging_datetimes)\n",
    "    df_pred['pred'] = post_pred_charge_proc_func(df_pred['pred'])\n",
    "    schedule = df_pred['pred']\n",
    "    solar_profile = df.loc[schedule.index]['pv_power_mw']\n",
    "    score = score_charging(schedule, solar_profile)\n",
    "    prop_max = prop_max_solar(schedule, solar_profile)\n",
    "    print(f\"Model: `{key}`    Score: {score:.3f}     Proportion of max: {100*prop_max:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.groupby(df_pred.index.date).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Finally we'll export the relevant code to our `batopt` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "    \n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
