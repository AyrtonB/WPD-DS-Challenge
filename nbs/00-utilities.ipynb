{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "forward-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-length",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "\n",
    "This notebook documents the general utility functions developed in this research\n",
    "\n",
    "<br>\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "major-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import junix\n",
    "from html.parser import HTMLParser\n",
    "from nbdev.export2html import convert_md\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import rankdata\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "import os\n",
    "import codecs\n",
    "from ipypb import track\n",
    "from warnings import warn\n",
    "from functools import partial\n",
    "from distutils.dir_util import copy_tree\n",
    "from collections.abc import Iterable, Sized\n",
    "from collections import defaultdict\n",
    "\n",
    "import sklearn \n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import is_classifier, clone\n",
    "from sklearn.utils.validation import indexable\n",
    "\n",
    "try:\n",
    "    from sklearn.metrics import check_scoring\n",
    "except ImportError:\n",
    "    from sklearn.metrics.scorer import check_scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-integral",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "french-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_nbs_dir = '.'\n",
    "docs_dir = '../docs'\n",
    "docs_nb_img_dir = f'{docs_dir}/img/nbs'\n",
    "nb_img_dir = '../img/nbs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-bacon",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Monkey Patching `skopt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stopped-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def bayes_search_CV_init(self, estimator, search_spaces, optimizer_kwargs=None,\n",
    "                         n_iter=50, scoring=None, fit_params=None, n_jobs=1,\n",
    "                         n_points=1, iid=True, refit=True, cv=None, verbose=0,\n",
    "                         pre_dispatch='2*n_jobs', random_state=None,\n",
    "                         error_score='raise', return_train_score=False):\n",
    "\n",
    "        self.search_spaces = search_spaces\n",
    "        self.n_iter = n_iter\n",
    "        self.n_points = n_points\n",
    "        self.random_state = random_state\n",
    "        self.optimizer_kwargs = optimizer_kwargs\n",
    "        self._check_search_space(self.search_spaces)\n",
    "        self.fit_params = fit_params\n",
    "        self.iid = None\n",
    "\n",
    "        super(BayesSearchCV, self).__init__(\n",
    "             estimator=estimator, scoring=scoring,\n",
    "             n_jobs=n_jobs, refit=refit, cv=cv, verbose=verbose,\n",
    "             pre_dispatch=pre_dispatch, error_score=error_score,\n",
    "             return_train_score=return_train_score)\n",
    "        \n",
    "BayesSearchCV.__init__ = bayes_search_CV_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-window",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "amazing-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def bayes_search_CV__fit(self, X, y, groups, parameter_iterable):\n",
    "    \"\"\"\n",
    "    Actual fitting,  performing the search over parameters.\n",
    "    Taken from https://github.com/scikit-learn/scikit-learn/blob/0.18.X\n",
    "                .../sklearn/model_selection/_search.py\n",
    "    \"\"\"\n",
    "    estimator = self.estimator\n",
    "    cv = sklearn.model_selection._validation.check_cv(\n",
    "        self.cv, y, classifier=is_classifier(estimator))\n",
    "    self.scorer_ = check_scoring(\n",
    "        self.estimator, scoring=self.scoring)\n",
    "\n",
    "    X, y, groups = indexable(X, y, groups)\n",
    "    n_splits = cv.get_n_splits(X, y, groups)\n",
    "    if self.verbose > 0 and isinstance(parameter_iterable, Sized):\n",
    "        n_candidates = len(parameter_iterable)\n",
    "        print(\"Fitting {0} folds for each of {1} candidates, totalling\"\n",
    "              \" {2} fits\".format(n_splits, n_candidates,\n",
    "                                 n_candidates * n_splits))\n",
    "\n",
    "    base_estimator = clone(self.estimator)\n",
    "    pre_dispatch = self.pre_dispatch\n",
    "\n",
    "    cv_iter = list(cv.split(X, y, groups))\n",
    "    out = Parallel(\n",
    "        n_jobs=self.n_jobs, verbose=self.verbose,\n",
    "        pre_dispatch=pre_dispatch\n",
    "    )(delayed(sklearn.model_selection._validation._fit_and_score)(\n",
    "            clone(base_estimator),\n",
    "            X, y, self.scorer_,\n",
    "            train, test, self.verbose, parameters,\n",
    "            fit_params=self.fit_params,\n",
    "            return_train_score=self.return_train_score,\n",
    "            return_n_test_samples=True,\n",
    "            return_times=True, return_parameters=True,\n",
    "            error_score=self.error_score\n",
    "        )\n",
    "        for parameters in parameter_iterable\n",
    "        for train, test in cv_iter)\n",
    "\n",
    "    # if one choose to see train score, \"out\" will contain train score info\n",
    "    if self.return_train_score:\n",
    "        (train_scores, test_scores, n_test_samples,\n",
    "         fit_time, score_time, parameters) = zip(*out)\n",
    "    else:\n",
    "        from warnings import warn\n",
    "        (fit_failed, test_scores, n_test_samples,\n",
    "         fit_time, score_time, parameters) = zip(*[a.values() for a in out])\n",
    "\n",
    "    candidate_params = parameters[::n_splits]\n",
    "    n_candidates = len(candidate_params)\n",
    "\n",
    "    results = dict()\n",
    "\n",
    "    def _store(key_name, array, weights=None, splits=False, rank=False):\n",
    "        \"\"\"A small helper to store the scores/times to the cv_results_\"\"\"\n",
    "        array = np.array(array, dtype=np.float64).reshape(n_candidates,\n",
    "                                                          n_splits)\n",
    "        if splits:\n",
    "            for split_i in range(n_splits):\n",
    "                results[\"split%d_%s\"\n",
    "                        % (split_i, key_name)] = array[:, split_i]\n",
    "\n",
    "        array_means = np.average(array, axis=1, weights=weights)\n",
    "        results['mean_%s' % key_name] = array_means\n",
    "        # Weighted std is not directly available in numpy\n",
    "        array_stds = np.sqrt(np.average((array -\n",
    "                                         array_means[:, np.newaxis]) ** 2,\n",
    "                                        axis=1, weights=weights))\n",
    "        results['std_%s' % key_name] = array_stds\n",
    "\n",
    "        if rank:\n",
    "            results[\"rank_%s\" % key_name] = np.asarray(\n",
    "                rankdata(-array_means, method='min'), dtype=np.int32)\n",
    "\n",
    "    # Computed the (weighted) mean and std for test scores alone\n",
    "    # NOTE test_sample counts (weights) remain the same for all candidates n_test_samples\n",
    "    n_test_samples = np.array(n_test_samples[:n_splits],\n",
    "                                  dtype=np.int)\n",
    "\n",
    "    _store('test_score', test_scores, splits=True, rank=True,\n",
    "           weights=n_test_samples if self.iid else None)\n",
    "    if self.return_train_score:\n",
    "        _store('train_score', train_scores, splits=True)\n",
    "    _store('fit_time', fit_time)\n",
    "    _store('score_time', score_time)\n",
    "\n",
    "    best_index = np.flatnonzero(results[\"rank_test_score\"] == 1)[0]\n",
    "    best_parameters = candidate_params[best_index]\n",
    "\n",
    "    # Use one MaskedArray and mask all the places where the param is not\n",
    "    # applicable for that candidate. Use defaultdict as each candidate may\n",
    "    # not contain all the params\n",
    "    param_results = defaultdict(partial(np.ma.array,\n",
    "                                        np.empty(n_candidates,),\n",
    "                                        mask=True,\n",
    "                                        dtype=object))\n",
    "    for cand_i, params in enumerate(candidate_params):\n",
    "        for name, value in params.items():\n",
    "            # An all masked empty array gets created for the key\n",
    "            # `\"param_%s\" % name` at the first occurence of `name`.\n",
    "            # Setting the value at an index also unmasks that index\n",
    "            param_results[\"param_%s\" % name][cand_i] = value\n",
    "\n",
    "    results.update(param_results)\n",
    "\n",
    "    # Store a list of param dicts at est_sample_counts = np.array(n_test_samples[:n_splits], key 'params'\n",
    "    results['params'] = candidate_params\n",
    "\n",
    "    self.cv_results_ = results\n",
    "    self.best_index_ = best_index\n",
    "    self.n_splits_ = n_splits\n",
    "\n",
    "    if self.refit:\n",
    "        # fit the best estimator using the entire dataset\n",
    "        # clone first to work around broken estimators\n",
    "        best_estimator = clone(base_estimator).set_params(\n",
    "            **best_parameters)\n",
    "        if y is not None:\n",
    "            best_estimator.fit(X, y, **self.fit_params)\n",
    "        else:\n",
    "            best_estimator.fit(X, **self.fit_params)\n",
    "        self.best_estimator_ = best_estimator\n",
    "    return self\n",
    "\n",
    "BayesSearchCV._fit = bayes_search_CV__fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-gender",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Custom `sklearn` Models\n",
    "\n",
    "We require access to the dataframe index in order to evaluate the discharge optimisation predictions accurately (as we need to group predictions by date), however, standard `sklearn` strips them and returns only numpy arrays. We'll create a custom model that preserves the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "endless-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def add_series_index(idx_arg_pos=0):\n",
    "    def decorator(func):\n",
    "        def decorator_wrapper(*args, **kwargs):\n",
    "            input_s = args[idx_arg_pos]\n",
    "            assert isinstance(input_s, (pd.Series, pd.DataFrame))\n",
    "            result = pd.Series(func(*args, **kwargs), index=input_s.index)\n",
    "            return result\n",
    "        return decorator_wrapper\n",
    "    return decorator\n",
    "\n",
    "class PandasRandomForestRegressor(RandomForestRegressor):\n",
    "    def __init__(self, n_estimators=100, *, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None, score_func=None):\n",
    "        super().__init__(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, min_weight_fraction_leaf=min_weight_fraction_leaf, max_features=max_features, max_leaf_nodes=max_leaf_nodes, min_impurity_decrease=min_impurity_decrease, min_impurity_split=min_impurity_split, bootstrap=bootstrap, oob_score=oob_score, n_jobs=n_jobs, random_state=random_state, verbose=verbose, warm_start=warm_start, ccp_alpha=ccp_alpha, max_samples=max_samples)\n",
    "    \n",
    "        if score_func is None:\n",
    "            self.score_func = r2_score\n",
    "        else:\n",
    "            self.score_func = score_func\n",
    "            \n",
    "    @add_series_index(1)\n",
    "    def predict(self, X):\n",
    "        pred = super().predict(X)\n",
    "        return pred\n",
    "    \n",
    "    def score(self, X, y, *args, **kwargs):        \n",
    "        y_pred = self.predict(X)\n",
    "        score = self.score_func(y, y_pred, *args, **kwargs)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "respective-fabric",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PandasRandomForestRegressor(score_func=<function r2_score at 0x00000279B206CA60>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_RF = PandasRandomForestRegressor()\n",
    "\n",
    "pandas_RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-springfield",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Converting Notebooks to Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "local-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def convert_file_to_json(filepath):\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf8') as f:\n",
    "        contents = f.read()\n",
    "        f.close()\n",
    "\n",
    "    return json.loads(contents)\n",
    "\n",
    "junix.exporter.convert_file_to_json = convert_file_to_json\n",
    "\n",
    "def encode_file_as_utf8(fp):\n",
    "    with codecs.open(fp, 'r') as file:\n",
    "        contents = file.read(1048576)\n",
    "        file.close()\n",
    "\n",
    "        if not contents:\n",
    "            pass\n",
    "        else:\n",
    "            with codecs.open(fp, 'w', 'utf-8') as file:\n",
    "                file.write(contents)\n",
    "            \n",
    "def convert_nbs_to_md(nbs_dir, docs_nb_img_dir, docs_dir):\n",
    "    nb_files = [f for f in os.listdir(nbs_dir) if f[-6:]=='.ipynb']\n",
    "\n",
    "    for nb_file in track(nb_files):\n",
    "        nb_fp = f'{nbs_dir}/{nb_file}'\n",
    "        junix.export_images(nb_fp, docs_nb_img_dir)\n",
    "        convert_md(nb_fp, docs_dir, img_path=f'{docs_nb_img_dir}/', jekyll=False)\n",
    "\n",
    "        md_fp =  docs_dir + '/'+ nb_file.replace('.ipynb', '') + '.md'\n",
    "        encode_file_as_utf8(md_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hearing-postage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><span class=\"Text-label\" style=\"display:inline-block; overflow:hidden; white-space:nowrap; text-overflow:ellipsis; min-width:0; max-width:15ex; vertical-align:middle; text-align:right\"></span>\n",
       "<progress style=\"width:60ex\" max=\"8\" value=\"8\" class=\"Progress-main\"/></progress>\n",
       "<span class=\"Progress-label\"><strong>100%</strong></span>\n",
       "<span class=\"Iteration-label\">8/8</span>\n",
       "<span class=\"Time-label\">[00:03<00:00, 0.32s/it]</span></div>"
      ],
      "text/plain": [
       "\u001b[A\u001b[2K\r",
       " [████████████████████████████████████████████████████████████] 8/8 [00:03<00:00, 0.32s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "convert_nbs_to_md(dev_nbs_dir, docs_nb_img_dir, docs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-bankruptcy",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Cleaning Markdown Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "collectible-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tags = []\n",
    "    \n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        self.tags.append(self.get_starttag_text())\n",
    "\n",
    "    def handle_endtag(self, tag):\n",
    "        self.tags.append(f\"</{tag}>\")\n",
    "        \n",
    "get_substring_idxs = lambda string, substring: [num for num in range(len(string)-len(substring)+1) if string[num:num+len(substring)]==substring]\n",
    "\n",
    "def convert_df_to_md(df):\n",
    "    idx_col = df.columns[0]\n",
    "    df = df.set_index(idx_col)\n",
    "    \n",
    "    if idx_col == 'Unnamed: 0':\n",
    "        df.index.name = ''\n",
    "    \n",
    "    table_md = df.to_markdown()\n",
    "    \n",
    "    return table_md\n",
    "\n",
    "def extract_div_to_md_table(start_idx, end_idx, table_and_div_tags, file_txt):\n",
    "    n_start_divs_before = table_and_div_tags[:start_idx].count('<div>')\n",
    "    n_end_divs_before = table_and_div_tags[:end_idx].count('</div>')\n",
    "    \n",
    "    div_start_idx = get_substring_idxs(file_txt, '<div>')[n_start_divs_before-1]\n",
    "    div_end_idx = get_substring_idxs(file_txt, '</div>')[n_end_divs_before]\n",
    "\n",
    "    div_txt = file_txt[div_start_idx:div_end_idx]\n",
    "    potential_dfs = pd.read_html(div_txt)\n",
    "    \n",
    "    assert len(potential_dfs) == 1, 'Multiple tables were found when there should be only one'\n",
    "    df = potential_dfs[0]\n",
    "    md_table = convert_df_to_md(df)\n",
    "\n",
    "    return div_txt, md_table\n",
    "\n",
    "def extract_div_to_md_tables(md_fp):\n",
    "    with open(md_fp, 'r') as f:\n",
    "        file_txt = f.read()\n",
    "        \n",
    "    parser = MyHTMLParser()\n",
    "    parser.feed(file_txt)\n",
    "\n",
    "    table_and_div_tags = [tag for tag in parser.tags if tag in ['<div>', '</div>', '<table border=\"1\" class=\"dataframe\">', '</table>']]\n",
    "    \n",
    "    table_start_tag_idxs = [i for i, tag in enumerate(table_and_div_tags) if tag=='<table border=\"1\" class=\"dataframe\">']\n",
    "    table_end_tag_idxs = [table_start_tag_idx+table_and_div_tags[table_start_tag_idx:].index('</table>') for table_start_tag_idx in table_start_tag_idxs]\n",
    "\n",
    "    div_to_md_tables = []\n",
    "\n",
    "    for start_idx, end_idx in zip(table_start_tag_idxs, table_end_tag_idxs):\n",
    "        div_txt, md_table = extract_div_to_md_table(start_idx, end_idx, table_and_div_tags, file_txt)\n",
    "        div_to_md_tables += [(div_txt, md_table)]\n",
    "        \n",
    "    return div_to_md_tables\n",
    "\n",
    "def clean_md_file_tables(md_fp):\n",
    "    div_to_md_tables = extract_div_to_md_tables(md_fp)\n",
    "    \n",
    "    with open(md_fp, 'r') as f:\n",
    "        md_file_text = f.read()\n",
    "\n",
    "    for div_txt, md_txt in div_to_md_tables:\n",
    "        md_file_text = md_file_text.replace(div_txt, md_txt)\n",
    "\n",
    "    with open(md_fp, 'w') as f:\n",
    "        f.write(md_file_text)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sought-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_fps = [f'{docs_dir}/{f}' for f in os.listdir(docs_dir) if f[-3:]=='.md' if f!='00-utilities.md']\n",
    "\n",
    "for md_fp in md_fps:\n",
    "    div_to_md_tables = clean_md_file_tables(md_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-onion",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Cleaning Image Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "united-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def clean_md_file_img_fps(md_fp):\n",
    "    with open(md_fp, 'r') as f:\n",
    "        md_file_text = f.read()\n",
    "\n",
    "    md_file_text = md_file_text.replace('../docs/img/nbs', 'img/nbs')\n",
    "\n",
    "    with open(md_fp, 'w') as f:\n",
    "        f.write(md_file_text)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "horizontal-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "for md_fp in md_fps:\n",
    "    clean_md_file_img_fps(md_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-heating",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Plotting\n",
    "\n",
    "`AxTransformer` enables conversion from data coordinates to tick locations, `set_date_ticks` allows custom date ranges to be applied to plots (including a seaborn heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sized-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "class AxTransformer:\n",
    "    def __init__(self, datetime_vals=False):\n",
    "        self.datetime_vals = datetime_vals\n",
    "        self.lr = linear_model.LinearRegression()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def process_tick_vals(self, tick_vals):\n",
    "        if not isinstance(tick_vals, Iterable) or isinstance(tick_vals, str):\n",
    "            tick_vals = [tick_vals]\n",
    "            \n",
    "        if self.datetime_vals == True:\n",
    "            tick_vals = pd.to_datetime(tick_vals).astype(int).values\n",
    "            \n",
    "        tick_vals = np.array(tick_vals)\n",
    "            \n",
    "        return tick_vals\n",
    "    \n",
    "    def fit(self, ax, axis='x'):\n",
    "        axis = getattr(ax, f'get_{axis}axis')()\n",
    "        \n",
    "        tick_locs = axis.get_ticklocs()\n",
    "        tick_vals = self.process_tick_vals([label._text for label in axis.get_ticklabels()])\n",
    "        \n",
    "        self.lr.fit(tick_vals.reshape(-1, 1), tick_locs)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def transform(self, tick_vals):        \n",
    "        tick_vals = self.process_tick_vals(tick_vals)\n",
    "        tick_locs = self.lr.predict(np.array(tick_vals).reshape(-1, 1))\n",
    "        \n",
    "        return tick_locs\n",
    "    \n",
    "def set_date_ticks(ax, start_date, end_date, axis='y', date_format='%Y-%m-%d', **date_range_kwargs):\n",
    "    dt_rng = pd.date_range(start_date, end_date, **date_range_kwargs)\n",
    "\n",
    "    ax_transformer = AxTransformer(datetime_vals=True)\n",
    "    ax_transformer.fit(ax, axis=axis)\n",
    "    \n",
    "    getattr(ax, f'set_{axis}ticks')(ax_transformer.transform(dt_rng))\n",
    "    getattr(ax, f'set_{axis}ticklabels')(dt_rng.strftime(date_format))\n",
    "    \n",
    "    ax.tick_params(axis=axis, which='both', bottom=True, top=False, labelbottom=True)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-security",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Finally we'll export the relevant code to our `batopt` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "spiritual-soldier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00-utilities.ipynb.\n",
      "Converted 01-data-cleaning.ipynb.\n",
      "Converted 02-battery-discharge.ipynb.\n",
      "Converted 03-battery-charge.ipynb.\n",
      "Converted 03-pv-forecast.ipynb.\n",
      "Converted 04-battery-optimisation.ipynb.\n",
      "Converted 05-evaluation.ipynb.\n",
      "Converted 06-pipeline.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "    \n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "batopt",
   "language": "python",
   "name": "batopt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
