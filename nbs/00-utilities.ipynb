{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interpreted-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-dialogue",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "\n",
    "This notebook documents the general utility functions developed in this research\n",
    "\n",
    "<br>\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "domestic-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import junix\n",
    "from html.parser import HTMLParser\n",
    "from nbdev.export2html import convert_md\n",
    "\n",
    "import os\n",
    "import codecs\n",
    "from ipypb import track\n",
    "from warnings import warn\n",
    "from distutils.dir_util import copy_tree\n",
    "from collections.abc import Iterable\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-torture",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "balanced-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_nbs_dir = '.'\n",
    "docs_dir = '../docs'\n",
    "docs_nb_img_dir = f'{docs_dir}/img/nbs'\n",
    "nb_img_dir = '../img/nbs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-battery",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Converting Notebooks to Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adolescent-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def encode_file_as_utf8(fp):\n",
    "    with codecs.open(fp, 'r') as file:\n",
    "        contents = file.read(1048576)\n",
    "        file.close()\n",
    "\n",
    "        if not contents:\n",
    "            pass\n",
    "        else:\n",
    "            with codecs.open(fp, 'w', 'utf-8') as file:\n",
    "                file.write(contents)\n",
    "            \n",
    "def convert_nbs_to_md(nbs_dir, docs_nb_img_dir, docs_dir):\n",
    "    nb_files = [f for f in os.listdir(nbs_dir) if f[-6:]=='.ipynb']\n",
    "\n",
    "    for nb_file in track(nb_files):\n",
    "        nb_fp = f'{nbs_dir}/{nb_file}'\n",
    "        junix.export_images(nb_fp, docs_nb_img_dir)\n",
    "        convert_md(nb_fp, docs_dir, img_path=f'{docs_nb_img_dir}/', jekyll=False)\n",
    "\n",
    "        md_fp =  docs_dir + '/'+ nb_file.replace('.ipynb', '') + '.md'\n",
    "        encode_file_as_utf8(md_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dominican-stockholm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><span class=\"Text-label\" style=\"display:inline-block; overflow:hidden; white-space:nowrap; text-overflow:ellipsis; min-width:0; max-width:15ex; vertical-align:middle; text-align:right\"></span>\n",
       "<progress style=\"width:60ex\" max=\"2\" value=\"2\" class=\"Progress-main\"/></progress>\n",
       "<span class=\"Progress-label\"><strong>100%</strong></span>\n",
       "<span class=\"Iteration-label\">2/2</span>\n",
       "<span class=\"Time-label\">[00:00<00:00, 0.23s/it]</span></div>"
      ],
      "text/plain": [
       "\u001b[A\u001b[2K\r",
       " [████████████████████████████████████████████████████████████] 2/2 [00:00<00:00, 0.23s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "convert_nbs_to_md(dev_nbs_dir, docs_nb_img_dir, docs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-miniature",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Cleaning Markdown Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "drawn-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tags = []\n",
    "    \n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        self.tags.append(self.get_starttag_text())\n",
    "\n",
    "    def handle_endtag(self, tag):\n",
    "        self.tags.append(f\"</{tag}>\")\n",
    "        \n",
    "get_substring_idxs = lambda string, substring: [num for num in range(len(string)-len(substring)+1) if string[num:num+len(substring)]==substring]\n",
    "\n",
    "def convert_df_to_md(df):\n",
    "    idx_col = df.columns[0]\n",
    "    df = df.set_index(idx_col)\n",
    "    \n",
    "    if idx_col == 'Unnamed: 0':\n",
    "        df.index.name = ''\n",
    "    \n",
    "    table_md = df.to_markdown()\n",
    "    \n",
    "    return table_md\n",
    "\n",
    "def extract_div_to_md_table(start_idx, end_idx, table_and_div_tags, file_txt):\n",
    "    n_start_divs_before = table_and_div_tags[:start_idx].count('<div>')\n",
    "    n_end_divs_before = table_and_div_tags[:end_idx].count('</div>')\n",
    "    \n",
    "    div_start_idx = get_substring_idxs(file_txt, '<div>')[n_start_divs_before-1]\n",
    "    div_end_idx = get_substring_idxs(file_txt, '</div>')[n_end_divs_before]\n",
    "\n",
    "    div_txt = file_txt[div_start_idx:div_end_idx]\n",
    "    potential_dfs = pd.read_html(div_txt)\n",
    "    \n",
    "    assert len(potential_dfs) == 1, 'Multiple tables were found when there should be only one'\n",
    "    df = potential_dfs[0]\n",
    "    md_table = convert_df_to_md(df)\n",
    "\n",
    "    return div_txt, md_table\n",
    "\n",
    "def extract_div_to_md_tables(md_fp):\n",
    "    with open(md_fp, 'r') as f:\n",
    "        file_txt = f.read()\n",
    "        \n",
    "    parser = MyHTMLParser()\n",
    "    parser.feed(file_txt)\n",
    "\n",
    "    table_and_div_tags = [tag for tag in parser.tags if tag in ['<div>', '</div>', '<table border=\"1\" class=\"dataframe\">', '</table>']]\n",
    "    \n",
    "    table_start_tag_idxs = [i for i, tag in enumerate(table_and_div_tags) if tag=='<table border=\"1\" class=\"dataframe\">']\n",
    "    table_end_tag_idxs = [table_start_tag_idx+table_and_div_tags[table_start_tag_idx:].index('</table>') for table_start_tag_idx in table_start_tag_idxs]\n",
    "\n",
    "    div_to_md_tables = []\n",
    "\n",
    "    for start_idx, end_idx in zip(table_start_tag_idxs, table_end_tag_idxs):\n",
    "        div_txt, md_table = extract_div_to_md_table(start_idx, end_idx, table_and_div_tags, file_txt)\n",
    "        div_to_md_tables += [(div_txt, md_table)]\n",
    "        \n",
    "    return div_to_md_tables\n",
    "\n",
    "def clean_md_file_tables(md_fp):\n",
    "    div_to_md_tables = extract_div_to_md_tables(md_fp)\n",
    "    \n",
    "    with open(md_fp, 'r') as f:\n",
    "        md_file_text = f.read()\n",
    "\n",
    "    for div_txt, md_txt in div_to_md_tables:\n",
    "        md_file_text = md_file_text.replace(div_txt, md_txt)\n",
    "\n",
    "    with open(md_fp, 'w') as f:\n",
    "        f.write(md_file_text)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bearing-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_fps = [f'{docs_dir}/{f}' for f in os.listdir(docs_dir) if f[-3:]=='.md' if f!='00-documentation.md']\n",
    "\n",
    "for md_fp in md_fps:\n",
    "    div_to_md_tables = clean_md_file_tables(md_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-standing",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Cleaning Image Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "colored-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def clean_md_file_img_fps(md_fp):\n",
    "    with open(md_fp, 'r') as f:\n",
    "        md_file_text = f.read()\n",
    "\n",
    "    md_file_text = md_file_text.replace('../docs/img/nbs', 'img/nbs')\n",
    "\n",
    "    with open(md_fp, 'w') as f:\n",
    "        f.write(md_file_text)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "practical-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "for md_fp in md_fps:\n",
    "    clean_md_file_img_fps(md_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-journey",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Plotting\n",
    "\n",
    "`AxTransformer` enables conversion from data coordinates to tick locations, `set_date_ticks` allows custom date ranges to be applied to plots (including a seaborn heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "confidential-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "class AxTransformer:\n",
    "    def __init__(self, datetime_vals=False):\n",
    "        self.datetime_vals = datetime_vals\n",
    "        self.lr = linear_model.LinearRegression()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def process_tick_vals(self, tick_vals):\n",
    "        if not isinstance(tick_vals, Iterable) or isinstance(tick_vals, str):\n",
    "            tick_vals = [tick_vals]\n",
    "            \n",
    "        if self.datetime_vals == True:\n",
    "            tick_vals = pd.to_datetime(tick_vals).astype(int).values\n",
    "            \n",
    "        tick_vals = np.array(tick_vals)\n",
    "            \n",
    "        return tick_vals\n",
    "    \n",
    "    def fit(self, ax, axis='x'):\n",
    "        axis = getattr(ax, f'get_{axis}axis')()\n",
    "        \n",
    "        tick_locs = axis.get_ticklocs()\n",
    "        tick_vals = self.process_tick_vals([label._text for label in axis.get_ticklabels()])\n",
    "        \n",
    "        self.lr.fit(tick_vals.reshape(-1, 1), tick_locs)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def transform(self, tick_vals):        \n",
    "        tick_vals = self.process_tick_vals(tick_vals)\n",
    "        tick_locs = self.lr.predict(np.array(tick_vals).reshape(-1, 1))\n",
    "        \n",
    "        return tick_locs\n",
    "    \n",
    "def set_date_ticks(ax, start_date, end_date, axis='y', date_format='%Y-%m-%d', **date_range_kwargs):\n",
    "    dt_rng = pd.date_range(start_date, end_date, **date_range_kwargs)\n",
    "\n",
    "    ax_transformer = AxTransformer(datetime_vals=True)\n",
    "    ax_transformer.fit(ax, axis=axis)\n",
    "    \n",
    "    getattr(ax, f'set_{axis}ticks')(ax_transformer.transform(dt_rng))\n",
    "    getattr(ax, f'set_{axis}ticklabels')(dt_rng.strftime(date_format))\n",
    "    \n",
    "    ax.tick_params(axis=axis, which='both', bottom=True, top=False, labelbottom=True)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-garbage",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Finally we'll export the relevant code to our `batopt` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "prompt-college",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00-utilities.ipynb.\n",
      "Converted 01-data-loading.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "    \n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "batopt",
   "language": "python",
   "name": "batopt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
