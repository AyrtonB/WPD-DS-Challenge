{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ongoing-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp pv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-distribution",
   "metadata": {},
   "source": [
    "# Charging with PV Forecast\n",
    "\n",
    "Previously, we tried to produce a charge profile by constructing optimal charge profiles for each day, and then using these optimal charge profiles as targets in our models.\n",
    "\n",
    "Here we will try and predict the optimal charge profile by first forecasting PV, then constructing an optimal profile based on the forecast. The hope is that estimating solar PV is easier than estimating optimal charge profiles, which tend to be pretty spiky and have given us weird residuals. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-connection",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "traditional-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from moepy.lowess import quantile_model\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "from skopt.plots import plot_objective\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from batopt import clean, discharge, utils, charge\n",
    "\n",
    "import FEAutils as hlp\n",
    "\n",
    "from ipypb import track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-tattoo",
   "metadata": {},
   "source": [
    "### User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "improving-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = '../data/raw'\n",
    "intermediate_data_dir = '../data/intermediate'\n",
    "cache_data_dir = '../data/nb-cache'\n",
    "charge_opt_model_fp = '../models/charge_opt.sav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-acrylic",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recent-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def prepare_training_input_data(intermediate_data_dir, start_hour=5):\n",
    "    # Loading input data\n",
    "    df = clean.combine_training_datasets(intermediate_data_dir).interpolate(limit=1)\n",
    "    df_features = charge.construct_df_charge_features(df)\n",
    "    \n",
    "    # Filtering for overlapping feature and target data\n",
    "    dt_idx = pd.date_range(df_features.index.min(), df['pv_power_mw'].dropna().index.max()-pd.Timedelta(minutes=30), freq='30T')\n",
    "\n",
    "    s_pv = df.loc[dt_idx, 'pv_power_mw']\n",
    "    df_features = df_features.loc[dt_idx]\n",
    "        \n",
    "    # Filtering for evening datetimes\n",
    "    charging_datetimes = charge.extract_charging_datetimes(df_features, start_hour=start_hour)\n",
    "    \n",
    "    X = df_features.loc[charging_datetimes]\n",
    "    y = s_pv.loc[charging_datetimes]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-communication",
   "metadata": {},
   "source": [
    "### Fitting forecast model\n",
    "\n",
    "We will quickly fit a PV model just to check the residuals and that the data is all fine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "written-forth",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: DatetimeIndex(['2018-11-18 01:00:00+00:00', '2018-11-18 01:30:00+00:00',\\n               '2018-11-18 02:00:00+00:00', '2018-11-18 02:30:00+00:00',\\n               '2018-11-18 03:00:00+00:00',\\n               ...\\n               '2018-11-18 21:30:00+00:00', '2018-11-18 22:00:00+00:00',\\n               '2018-11-18 22:30:00+00:00', '2018-11-18 23:00:00+00:00',\\n               '2018-11-18 23:30:00+00:00'],\\n              dtype='datetime64[ns, UTC]', length=46, freq='30T'). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ef47df8392ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_training_input_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_data_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-d89945b2c38c>\u001b[0m in \u001b[0;36mprepare_training_input_data\u001b[0;34m(intermediate_data_dir, start_hour)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0ms_pv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pv_power_mw'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdf_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdt_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Filtering for evening datetimes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/batopt/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/batopt/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1110\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/batopt/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1054\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/batopt/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1263\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/batopt/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.max_seq_items\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"display.width\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m   1321\u001b[0m                     \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m                     \u001b[0;34m\"is no longer supported. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: DatetimeIndex(['2018-11-18 01:00:00+00:00', '2018-11-18 01:30:00+00:00',\\n               '2018-11-18 02:00:00+00:00', '2018-11-18 02:30:00+00:00',\\n               '2018-11-18 03:00:00+00:00',\\n               ...\\n               '2018-11-18 21:30:00+00:00', '2018-11-18 22:00:00+00:00',\\n               '2018-11-18 22:30:00+00:00', '2018-11-18 23:00:00+00:00',\\n               '2018-11-18 23:30:00+00:00'],\\n              dtype='datetime64[ns, UTC]', length=46, freq='30T'). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\""
     ]
    }
   ],
   "source": [
    "X, y = prepare_training_input_data(intermediate_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = clean.generate_kfold_preds(X.values, y.values, LinearRegression(), index=X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-collar",
   "metadata": {},
   "source": [
    "Analysing residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_pred.true, df_pred.pred, s=0.1)\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('Prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-seattle",
   "metadata": {},
   "source": [
    "### Analysing random days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def plot_random_day(df_pred, ax=None):\n",
    "    \"\"\"\n",
    "    View predicted and observed PV profiles\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    random_day = pd.to_datetime(np.random.choice(df_pred.index.date))\n",
    "    random_day = df_pred[df_pred.index.date==random_day]\n",
    "    plt.plot(random_day.true)\n",
    "    plt.plot(random_day.pred)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_day(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_solar_profile = discharge.sample_random_day(df_pred.pred).pipe(charge.extract_solar_profile)\n",
    "adj_random_solar_profile = discharge.flatten_peak(random_solar_profile)\n",
    "charge_profile = charge.construct_charge_profile(random_solar_profile, adj_random_solar_profile)\n",
    "plt.plot(charge_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-survivor",
   "metadata": {},
   "source": [
    "### Predicting charge based on PV forecast\n",
    "\n",
    "Now we will begin developing a unified approach for predicting PV and then optimising the battery charge schedule. \n",
    "\n",
    "We will also group by week. This should make the problem a bit harder, and help encourage the final model to generalise to lengthy unseen periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def generate_kfold_preds_weeks(X, y, model, groups, kfold_kwargs, index=None):\n",
    "    \"\"\"\n",
    "    Generate kfold preds, grouping by week\n",
    "    \"\"\"\n",
    "    \n",
    "    group_kfold = GroupKFold(**kfold_kwargs)\n",
    "    \n",
    "    df_pred = pd.DataFrame(columns=['pred', 'true'], index=np.arange(X.shape[0]))\n",
    "\n",
    "    for train_index, test_index in group_kfold.split(X, y, groups):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        df_pred.loc[test_index, 'true'] = y_test\n",
    "        df_pred.loc[test_index, 'pred'] = model.predict(X_test)\n",
    "\n",
    "    df_pred.sort_index()\n",
    "\n",
    "    if index is not None:\n",
    "        assert len(index) == df_pred.shape[0], 'The passed index must be the same length as X and y'\n",
    "        df_pred.index = index\n",
    "\n",
    "    return df_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def generate_kfold_charge_preds(X, y, model, groups, kfold_kwargs={'n_splits': 5}):\n",
    "    \"\"\"\n",
    "    Fit the PV forecasting model and calculate the optimal charge profile for predictions.\n",
    "    \"\"\"\n",
    "    df_pred = generate_kfold_preds_weeks(X.values, y.values, model, groups, kfold_kwargs=kfold_kwargs, index=X.index)\n",
    "    charge_pred = charge.construct_charge_s(df_pred.pred)\n",
    "    charge_pred = charge.post_pred_charge_proc_func(charge_pred)\n",
    "    return pd.DataFrame({'charge_pred': charge_pred, \n",
    "                         'pv_actual': df_pred.true,\n",
    "                         'pv_pred': df_pred.pred})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def predict_charge(X, model):\n",
    "    \"\"\"\n",
    "    Given a fitted PV forecast model and feature array X, get the optimal charge profile. \n",
    "    \"\"\"\n",
    "    pv_pred = pd.Series(model.predict(X), index=X.index)\n",
    "    charge_pred = charge.construct_charge_s(pv_pred)\n",
    "    charge_pred = charge.post_pred_charge_proc_func(charge_pred)\n",
    "    return pd.Series(charge_pred, index=X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-missouri",
   "metadata": {},
   "source": [
    "### Holding out final month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(arr, start_of_test_period): \n",
    "    train_arr = arr[:pd.to_datetime(start_of_test_period, utc=True)]\n",
    "    test_arr = arr[pd.to_datetime(start_of_test_period, utc=True):]\n",
    "    \n",
    "    return train_arr, test_arr\n",
    "\n",
    "start_of_test_period = '2018-09-15'\n",
    "\n",
    "X_train, X_test = get_train_test(X, start_of_test_period)\n",
    "y_train, y_test = get_train_test(y, start_of_test_period)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-nothing",
   "metadata": {},
   "source": [
    "### Fitting some models\n",
    "\n",
    "Now let's try executing this unified approach using k-fold CV, for 3 default models on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'std_linear': LinearRegression(),\n",
    "    'lasso': Lasso(),\n",
    "    'ridge': Ridge(),\n",
    "    'boosted': GradientBoostingRegressor(),\n",
    "    'random_forest': RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "# Define the week groups\n",
    "week_groups = X_train.index.year + X_train.index.isocalendar().week/52\n",
    "\n",
    "for key in models:\n",
    "    charge_pred_df = generate_kfold_charge_preds(X_train, y_train, models[key], week_groups)\n",
    "    score = charge.score_charging(charge_pred_df.charge_pred, charge_pred_df.pv_actual)\n",
    "    pv_mse = np.mean(np.square(charge_pred_df.pv_actual - charge_pred_df.pv_pred))\n",
    "    solar_exploit_pct = 100*charge.prop_max_solar(charge_pred_df.charge_pred, charge_pred_df.pv_actual)\n",
    "    print(\"{}: PV MSE: {:.2f}, score: {:.2f}, solar exploit: {:.2f}%\".format(key, pv_mse, score, solar_exploit_pct))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-estate",
   "metadata": {},
   "source": [
    "Interestingly, there is little difference between the models in terms of solar exploit, even though there are large differences in the MSE of the PV forecasts. For our previous attempt at the charging task, the linear model was much worse than the boosted model and RF in terms of solar exploit. This suggests that a weak (or under-fitted) estimator of solar PV actually performs quite well when it comes to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = LinearRegression()\n",
    "best_model.fit(X_train, y_train)\n",
    "preds = predict_charge(X_test, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "100*charge.prop_max_solar(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns, 1e6*best_model.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-event",
   "metadata": {},
   "source": [
    "Running the above analysis it seems like solar_locations 1 and 4 do not contribute much at all to the regression models: both are over an order of magnitude smaller than the others. Best to remove these when processing the data (for the moment this is `charge.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in X_train.columns if 'solar_location4' not in c and 'solar_location1' not in c]\n",
    "X_train_reduced, X_test_reduced = X_train.filter(features), X_test.filter(features)\n",
    "\n",
    "charge_pred_df = generate_kfold_charge_preds(X_train_reduced, y_train, LinearRegression(), week_groups)\n",
    "score = charge.score_charging(charge_pred_df.charge_pred, charge_pred_df.pv_actual)\n",
    "pv_mse = np.mean(np.square(charge_pred_df.pv_actual - charge_pred_df.pv_pred))\n",
    "solar_exploit_pct = 100*charge.prop_max_solar(charge_pred_df.charge_pred, charge_pred_df.pv_actual)\n",
    "print(\"PV MSE: {:.2f}, score: {:.2f}, solar exploit: {:.2f}%\".format(pv_mse, score, solar_exploit_pct))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-approach",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_solar_exploit_calculator(solar_profile, charging_datetimes=None, scorer=False):\n",
    "    if charging_datetimes is None:\n",
    "        charging_datetimes = charge.extract_charging_datetimes(solar_profile)\n",
    "            \n",
    "    def calc_solar_exploitation(y, y_pred):\n",
    "        # Checking evening datetimes\n",
    "        if hasattr(y_pred, 'index') == True:\n",
    "            charging_datetimes = charge.extract_charging_datetimes(y_pred)\n",
    "            \n",
    "        assert y_pred.shape[0] == solar_profile.loc[charging_datetimes].shape[0], f'The prediction series must be the same length as the number of charging datetimes in the main dataframe, {y_pred.shape[0]} {s_demand.loc[evening_datetimes].shape[0]}'\n",
    "        \n",
    "        charge_pred = charge.construct_charge_s(y_pred)\n",
    "        charge_pred = charge.post_pred_charge_proc_func(charge_pred)\n",
    "        \n",
    "        exploitation_pct = 100 * charge.prop_max_solar(charge_pred, solar_profile.loc[charging_datetimes])\n",
    "\n",
    "        return exploitation_pct\n",
    "\n",
    "    if scorer == True:\n",
    "        return make_scorer(calc_solar_exploitation)\n",
    "    else:\n",
    "        return calc_solar_exploitation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-fountain",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "It seems like overfitting could be a substantial issue for charging. Trying some feature selection: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lasso(alpha=0.5)\n",
    "model.fit(X_train, y_train)\n",
    "coefs_df = pd.DataFrame({'feature': X_train.columns,\n",
    "              'coefs': model.coef_})\n",
    "features = coefs_df[abs(coefs_df.coefs) > 0].feature\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [f for f in X_train.columns if 'temp' not in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_max_solar_df(charge_pred_df):\n",
    "    return charge.prop_max_solar(charge_pred_df.charge_pred, charge_pred_df.pv_actual)\n",
    "\n",
    "X_train_reduced = X_train.filter(features)\n",
    "\n",
    "models = {\n",
    "    'std_linear': LinearRegression(),\n",
    "    'lasso': Lasso(),\n",
    "    'boosted': GradientBoostingRegressor(),\n",
    "    'random_forest': RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "# Define the week groups\n",
    "week_groups = X_train.index.year + X_train.index.isocalendar().week/52\n",
    "\n",
    "for key in models:\n",
    "    charge_pred_df = generate_kfold_charge_preds(X_train, y_train, models[key], week_groups)\n",
    "    score = charge.score_charging(charge_pred_df.charge_pred, charge_pred_df.pv_actual)\n",
    "    pv_mse = np.mean(np.square(charge_pred_df.pv_actual - charge_pred_df.pv_pred))    \n",
    "    solar_exploit_pct = 100*charge_pred_df.groupby(charge_pred_df.index.date).apply(prop_max_solar_df)\n",
    "    print(\"{}: PV MSE: {:.2f}, score: {:.2f}, solar exploit: {:.2f}%, std. solar exploit: {:.2f}\".format(key, \n",
    "                                                                                                         pv_mse, \n",
    "                                                                                                         score, \n",
    "                                                                                                         solar_exploit_pct.mean(),\n",
    "                                                                                                         solar_exploit_pct.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "charge_pred_df = generate_kfold_charge_preds(X_train, y_train, model, week_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,5, figsize=(15,3), dpi=125)\n",
    "\n",
    "for i in range(5):\n",
    "    random_day = pd.to_datetime(np.random.choice(charge_pred_df.index.date))\n",
    "    random_df = charge_pred_df[charge_pred_df.index.date == random_day]\n",
    "    axs[i].plot(random_df.pv_actual)\n",
    "    axs[i].plot(random_df.charge_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def predict_charge(X, model):\n",
    "    \"\"\"\n",
    "    Given a fitted PV forecast model and feature array X, get the optimal charge profile. \n",
    "    \"\"\"\n",
    "    pv_pred = pd.Series(model.predict(X), index=X.index)    \n",
    "    charge_pred = charge.construct_charge_s(pv_pred)\n",
    "    charge_pred = charge.post_pred_charge_proc_func(charge_pred)\n",
    "        \n",
    "    return pd.Series(charge_pred, index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "pv_pred = model.predict(X_test)\n",
    "\n",
    "charge_pred = predict_charge(X_test, model)\n",
    "\n",
    "charge_pred_df = pd.DataFrame({'charge_pred': charge_pred,\n",
    "              'pv_pred': pv_pred,\n",
    "              'pv_actual': y_test})\n",
    "\n",
    "solar_exploit_pct = 100*charge_pred_df.groupby(charge_pred_df.index.date).apply(prop_max_solar_df)\n",
    "\n",
    "print(\"Held out solar exploit: {:.2f}%\".format(solar_exploit_pct.mean(), ))\n",
    "print(\"Held out solar exploit (std): {:.2f}\".format(solar_exploit_pct.std(), ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=8\n",
    "\n",
    "fig, axs = plt.subplots(1,N, figsize=(15,3), dpi=125, sharey=True)\n",
    "\n",
    "for i in range(N):\n",
    "    random_day = pd.to_datetime(np.random.choice(charge_pred_df.index.date, replace=True))\n",
    "    random_df = charge_pred_df[charge_pred_df.index.date == random_day]\n",
    "    \n",
    "    axs[i].plot(random_df.pv_actual, c='b', alpha=1)\n",
    "    axs[i].plot(random_df.pv_pred, c='b', linestyle='--', alpha=0.2)\n",
    "    axs[i].plot(random_df.charge_pred, c='g')\n",
    "    axs[i].axhline(2.5, c='r', linestyle=':')\n",
    "    axs[i].set_xticks([])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "## X, y = prepare_training_input_data(intermediate_data_dir)\n",
    "\n",
    "start_of_test_period = '2018-09-15'\n",
    "\n",
    "X_train, X_test = get_train_test(X, start_of_test_period)\n",
    "y_train, y_test = get_train_test(y, start_of_test_period)\n",
    "\n",
    "charging_datetimes = charge.extract_charging_datetimes(X_train)\n",
    "solar_exploit_scorer = construct_solar_exploit_calculator(solar_profile=y, \n",
    "                                                            charging_datetimes=charging_datetimes, \n",
    "                                                            scorer=True)\n",
    "groups = charging_datetimes.date\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('pandas_RF', utils.PandasRandomForestRegressor())\n",
    "])\n",
    "\n",
    "search_spaces = {\n",
    "        'pandas_RF__min_samples_leaf': Integer(1, 20, 'uniform'),\n",
    "        'pandas_RF__criterion': Categorical(['mse', 'mae']),\n",
    "        'pandas_RF__n_estimators': Integer(10, 150, 'uniform'),\n",
    "        'pandas_RF__max_features': Categorical(['auto', 'sqrt']),\n",
    "        'pandas_RF__max_depth': Integer(5, 200, 'uniform'),\n",
    "        'pandas_RF__min_samples_split': Integer(2, 10, 'uniform'),\n",
    "        'pandas_RF__min_samples_leaf': Integer(1, 4, 'uniform'),\n",
    "        'pandas_RF__bootstrap': Categorical([True, False])\n",
    "}\n",
    "\n",
    "opt = utils.BayesSearchCV(\n",
    "    pipeline,\n",
    "    search_spaces,\n",
    "    n_iter=10,\n",
    "    verbose=1,\n",
    "    cv=4, \n",
    "    scoring=solar_exploit_scorer,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "fit_BayesSearchCV = False\n",
    "\n",
    "if fit_BayesSearchCV == True:\n",
    "    opt.fit(X_train, y_train, groups=groups)\n",
    "\n",
    "    print(f'validation score: {opt.best_score_}')\n",
    "    print(f'held out score: {opt.score(X_test, y_test)}')\n",
    "    print(f'best params: {opt.best_params_}')\n",
    "\n",
    "    _ = plot_objective(opt.optimizer_results_[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-symbol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def fit_and_save_pv_model(X, y, pv_model_fp, model_class=LinearRegression, **model_params):\n",
    "    model = model_class(**model_params)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    with open(pv_model_fp, 'wb') as fp:\n",
    "        joblib.dump(model, fp)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def optimise_latest_test_charge_profile(raw_data_dir, intermediate_data_dir, pv_model_fp, latest_submission_template_name=None):\n",
    "    df_features = charge.prepare_latest_test_feature_data(raw_data_dir, intermediate_data_dir, latest_submission_template_name=latest_submission_template_name)\n",
    "    charging_datetimes = charge.extract_charging_datetimes(df_features)\n",
    "    X_test = df_features.loc[charging_datetimes]\n",
    "    \n",
    "    model = discharge.load_trained_model(pv_model_fp)\n",
    "    charge_profile = predict_charge(X_test, model)\n",
    "    \n",
    "    s_charge_profile = pd.Series(charge_profile, index=charging_datetimes)\n",
    "    s_charge_profile = s_charge_profile.reindex(df_features.index).fillna(0)\n",
    "    s_charge_profile = charge.post_pred_charge_proc_func(s_charge_profile)\n",
    "    \n",
    "    assert charge.charge_is_valid(s_charge_profile), \"Charging profile is invalid\"\n",
    "    \n",
    "    return s_charge_profile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_model_fp = '../models/pv_model.sav'\n",
    "s_charge_profile = optimise_latest_test_charge_profile(raw_data_dir, intermediate_data_dir, pv_model_fp)\n",
    "\n",
    "s_charge_profile.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-checkout",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Finally we'll export the relevant code to our `batopt` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "    \n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-destination",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
